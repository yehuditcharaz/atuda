{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDsTUvKjwHBW"
      },
      "source": [
        "# Multimodal Retrieval Augmented Generation (RAG) with Gemini, Vertex AI Vector Search, and LangChain\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Part 1: Extraction, Summary and Storage Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXJpXzKrh2rJ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnc3gA2hdsFU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-cloud-aiplatform langchain-core langchain-google-vertexai langchain-text-splitters langchain-community \"unstructured[all-docs]\" pypdf pydantic lxml pillow matplotlib opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7,
          "status": "ok",
          "timestamp": 1736769577388,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "XRvKdaPDTznN",
        "outputId": "767798df-c31c-495d-92cf-d0be886b8903",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI4XETsAQ8JH"
      },
      "source": [
        "\n",
        "\n",
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1736769890543,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "GpYEyLsOh2rL",
        "outputId": "13fd9783-a257-4bda-d488-888462d9f5b4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1vKZZoEh2rL"
      },
      "source": [
        "### Define Google Cloud project information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJqZ76rJh2rM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"sublime-vine-445509-s8\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# For Vector Search Staging\n",
        "GCS_BUCKET = \"hashem_yaazor\"  # @param {type:\"string\"}\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57262621bd1c"
      },
      "source": [
        "### Initialize the Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D48gUW5-h2rM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=GCS_BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 86804,
          "status": "ok",
          "timestamp": 1736770061054,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "Gjbfmgdlmida",
        "outputId": "9d8a165e-724b-4d24-e8cd-03fc409504b3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!apt-get install -y poppler-utils # Install the poppler-utils package, which contains pdfinfo\n",
        "!pip install unstructured[pdf] # Install unstructured with extra dependencies for PDF support\n",
        "!apt install tesseract-ocr # Install the tesseract OCR engine\n",
        "!pip install pytesseract  # Install the Python wrapper for tesseract\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "!cp -R ~/nltk_data/tokenizers/punkt/PY3 ~/nltk_data/tokenizers/punkt/PY3_tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rtMowvm-yQ97",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "from google.cloud import storage\n",
        "from IPython.display import Image\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_google_vertexai import (\n",
        "    ChatVertexAI,\n",
        "    VectorSearchVectorStore,\n",
        "    VertexAI,\n",
        "    VertexAIEmbeddings,\n",
        ")\n",
        "from langchain_google_vertexai.vectorstores.document_storage import GCSDocumentStorage\n",
        "from unstructured.partition.pdf import partition_pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf3ee5d1686"
      },
      "source": [
        "### Define model information\n",
        "\n",
        "- [Vertex AI - Model Information](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eb39bdada39d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gemini-1.5-flash\"\n",
        "GEMINI_OUTPUT_TOKEN_LIMIT = 8192\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-004\"\n",
        "EMBEDDING_TOKEN_LIMIT = 4096\n",
        "\n",
        "TOKEN_LIMIT = min(GEMINI_OUTPUT_TOKEN_LIMIT, EMBEDDING_TOKEN_LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c919bd5a462"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7bKCQMFT7JT"
      },
      "source": [
        "#### Get documents and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KwbL89zcY39N",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Install documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps1G-cCfpibN"
      },
      "source": [
        "## Partition PDF tables, text, and images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jqLsy3iZ5t-R"
      },
      "source": [
        "### Extract data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a87cb1a097b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "pdf_folder_path = \"/content/\" if \"google.colab\" in sys.modules else \"data/\"\n",
        "pdf_file_name = \"/content/RFM עדכון 8.2.24.pdf\"\n",
        "\n",
        "# Extract images, tables, and chunk text from a PDF file.\n",
        "raw_pdf_elements = partition_pdf(\n",
        "    filename=pdf_file_name,\n",
        "    strategy=\"hi_res\",\n",
        "    extract_images_in_pdf=False,\n",
        "    extract_image_block_to_payload=False,\n",
        "    infer_table_structure=True,\n",
        "    chunking_strategy=\"by_title\",\n",
        "    max_characters=4000,\n",
        "    new_after_n_chars=3800,\n",
        "    combine_text_under_n_chars=2000,\n",
        "    unique_element_ids=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB9mHnyCgLKk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "tables_elements = []\n",
        "texts_elements = []\n",
        "for element in raw_pdf_elements:\n",
        "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "        tables_elements.append(element)\n",
        "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
        "        texts_elements.append(element)\n",
        "\n",
        "tables = [element.text for element in tables_elements]\n",
        "texts = [element.text for element in texts_elements]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6T6Ijf2ofCB"
      },
      "source": [
        "### Generate summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 2647791,
          "status": "ok",
          "timestamp": 1736422560553,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "3I7C9YRo3vGu",
        "outputId": "bce9dfb4-83bf-4463-b40f-c8a8b81f82e4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def generate_summaries(\n",
        "    chunks: list[str], summarize: bool = True\n",
        ") -> list[str]:\n",
        "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
        "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_text)\n",
        "    empty_response = RunnableLambda(\n",
        "        lambda x: AIMessage(content=\"Error processing document\")\n",
        "    )\n",
        "    model = VertexAI(\n",
        "        temperature=0, model_name=MODEL_NAME, max_output_tokens=TOKEN_LIMIT\n",
        "    ).with_fallbacks([empty_response])\n",
        "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
        "\n",
        "    summaries = []\n",
        "\n",
        "    if chunks:\n",
        "        if summarize:\n",
        "            summaries = summarize_chain.batch(chunks, {\"max_concurrency\": 1})\n",
        "        else:\n",
        "            summaries = chunks\n",
        "\n",
        "    return summaries\n",
        "\n",
        "text_summaries = generate_summaries(texts)\n",
        "table_summaries = generate_summaries(tables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "379ae4ffbf83",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def encode_image(image_path: str) -> str:\n",
        "    \"\"\"Getting the base64 string\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "\n",
        "def image_summarize(base64_image: str) -> str:\n",
        "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw image. \\\n",
        "    Give a concise summary of the image that is well optimized for retrieval.\n",
        "    If it's a table, extract all elements of the table.\n",
        "    If it's a graph, explain the findings in the graph.\n",
        "    Do not include any numbers that are not mentioned in the image.\n",
        "    \"\"\"\n",
        "    model = ChatVertexAI(model_name=MODEL_NAME, max_output_tokens=TOKEN_LIMIT)\n",
        "    msg = model.invoke(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"},\n",
        "                    },\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return msg.content\n",
        "\n",
        "\n",
        "def generate_img_summaries(path: str) -> tuple[list[str], list[str]]:\n",
        "    \"\"\"\n",
        "    Generate summaries and base64 encoded strings for images\n",
        "    path: Path to list of .jpg files extracted by Unstructured\n",
        "    \"\"\"\n",
        "\n",
        "    # Store base64 encoded images\n",
        "    img_base64_list = []\n",
        "\n",
        "    # Store image summaries\n",
        "    image_summaries = []\n",
        "\n",
        "    for root, _, files in os.walk(path):\n",
        "        for img_file in sorted(files):\n",
        "            if img_file.endswith(\".png\"):\n",
        "                base64_image = encode_image(os.path.join(root, img_file))\n",
        "                img_base64_list.append(base64_image)\n",
        "                image_summaries.append(image_summarize(base64_image))\n",
        "                time.sleep(5)\n",
        "    return img_base64_list, image_summaries\n",
        "\n",
        "\n",
        "# Image summaries\n",
        "img_base64_list, image_summaries = generate_img_summaries(\"/content/images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 49,
          "status": "ok",
          "timestamp": 1736422560554,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "oza41QT0PBFL",
        "outputId": "7e26daef-bbda-4cab-ab03-8cc2c9d23239",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def get_missing_summaries(\n",
        "    texts: list[str], summaries: list[str], indexes: bool = False\n",
        "    ) -> list[str]:\n",
        "    return [i if indexes else texts[i] for i, text in enumerate(summaries) if len(summaries[i])==0 or  summaries[i] =='Error processing document']\n",
        "\n",
        "print(len(get_missing_summaries(texts, text_summaries)))\n",
        "print(get_missing_summaries(texts, text_summaries))\n",
        "print(len(get_missing_summaries(tables, table_summaries)))\n",
        "print(get_missing_summaries(tables, table_summaries))\n",
        "print(get_missing_summaries(img_base64_list, image_summaries))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw1YLstEv49f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MAX_TRIES = 6 # @param {type: \"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "elapsed": 1354856,
          "status": "ok",
          "timestamp": 1736423915400,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "LogcSP5u8Ysb",
        "outputId": "af64bd16-8007-4927-d26c-4b934b3e0ba6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def resummarize_missing_summaries(\n",
        "    chunks: list[str], current_summaries: list[str], N: int, is_image: bool = False\n",
        "    ) -> list[str]:\n",
        "\n",
        "    summaries = current_summaries\n",
        "\n",
        "    chunks_to_summarize  = get_missing_summaries(chunks, current_summaries)\n",
        "    missing_summaries_indexes = get_missing_summaries(chunks, current_summaries, indexes=True)\n",
        "\n",
        "    if is_image:\n",
        "        new_summaries = [image_summarize(image) for image in chunks_to_summarize]\n",
        "    else:\n",
        "        if N == MAX_TRIES - 1:\n",
        "            new_summaries = generate_summaries(chunks_to_summarize, summarize=False)\n",
        "        else:\n",
        "            new_summaries = generate_summaries(chunks_to_summarize, summarize=True)\n",
        "\n",
        "    for i, summary in enumerate(new_summaries):\n",
        "        summaries[missing_summaries_indexes[i]] = new_summaries[i]\n",
        "\n",
        "    return summaries\n",
        "\n",
        "\n",
        "for i in range(MAX_TRIES):\n",
        "    text_summaries = resummarize_missing_summaries(texts, text_summaries, N=i)\n",
        "    table_summaries = resummarize_missing_summaries(tables, table_summaries, N=i)\n",
        "    image_summaries = resummarize_missing_summaries(img_base64_list, image_summaries, N=i, is_image=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b641a76265d0"
      },
      "source": [
        "## Create & Deploy Vertex AI Vector Search Index & Endpoint\n",
        "\n",
        "Skip this step if you already have Vector Search set up.\n",
        "\n",
        "- https://console.cloud.google.com/vertex-ai/matching-engine/indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c15693534ed1"
      },
      "source": [
        "- Create [`MatchingEngineIndex`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex)\n",
        "  - https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 24430,
          "status": "ok",
          "timestamp": 1736423939822,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "dad379accb68",
        "outputId": "104a90c1-d483-44b7-9507-2c7de0e31313",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings\n",
        "DIMENSIONS = 768  # Dimensions output from textembedding-gecko\n",
        "\n",
        "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=\"mm_rag_langchain_index\",\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Multimodal RAG LangChain Index\",\n",
        "    index_update_method=\"STREAM_UPDATE\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add71035aaa1"
      },
      "source": [
        "- Create [`MatchingEngineIndexEndpoint`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndexEndpoint)\n",
        "  - https://cloud.google.com/vertex-ai/docs/vector-search/deploy-index-public"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1691,
          "status": "ok",
          "timestamp": 1736423941492,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "140c0142b90f",
        "outputId": "1c4f5dee-03da-4a34-ddb5-0ee7c5484f93",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = \"mm_rag_langchain_index_endpoint\"\n",
        "\n",
        "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=DEPLOYED_INDEX_ID,\n",
        "    description=\"Multimodal RAG LangChain Index Endpoint\",\n",
        "    public_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6adda75cab6"
      },
      "source": [
        "- Deploy Index to Index Endpoint\n",
        "  - NOTE: This will take a while to run.\n",
        "  - You can stop this cell after starting it instead of waiting for deployment.\n",
        "  - You can check the status at https://console.cloud.google.com/vertex-ai/matching-engine/indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1811102,
          "status": "ok",
          "timestamp": 1736425752592,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "4a02468a018b",
        "outputId": "7ee3c1e1-8368-44c2-c3e5-4d2503410863",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "index_endpoint = index_endpoint.deploy_index(\n",
        "    index=index, deployed_index_id=\"mm_rag_langchain_deployed_index\"\n",
        ")\n",
        "index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8475f61ef9"
      },
      "source": [
        "## Create retriever & load documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487ad4e4ccac"
      },
      "source": [
        "- Create [`VectorSearchVectorStore`](https://python.langchain.com/api_reference/google_vertexai/vectorstores/langchain_google_vertexai.vectorstores.vectorstores.VectorSearchVectorStore.html) with Vector Search Index ID and Endpoint ID.\n",
        "- Use [`textembedding-gecko`](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings) as embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e49355d04889",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# The vectorstore to use to index the summaries\n",
        "vectorstore = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=LOCATION,\n",
        "    gcs_bucket_name=GCS_BUCKET,\n",
        "    index_id=index.name,\n",
        "    endpoint_id=index_endpoint.name,\n",
        "    embedding=VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
        "    stream_update=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67a4b0490b45"
      },
      "source": [
        "- Create Multi-Vector Retriever using the vector store you created.\n",
        "- Since vector stores only contain the embedding and an ID, you'll also need to create a document store indexed by ID to get the original source documents after searching for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eVH5GhWtdJI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(GCS_BUCKET)\n",
        "    if not bucket.exists():\n",
        "        raise ValueError(f\"Bucket '{GCS_BUCKET}' does not exist.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e92ff890483",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "docstore = GCSDocumentStorage(bucket, \"RFM_chunks\")\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "retriever_multi_vector_img = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96b37cf7dc47"
      },
      "source": [
        "- Load data into Document Store and Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a92a4b04319",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "chunks_documents = [\n",
        "    Document(page_content=text_element.text,\n",
        "             metadata={**text_element.metadata.to_dict(), id_key: text_element.id})\n",
        "    for text_element in texts_elements\n",
        "] + [\n",
        "    Document(page_content=table_element.text,\n",
        "             metadata={**table_element.metadata.to_dict(), id_key: table_element.id})\n",
        "    for table_element in tables_elements\n",
        "] + [\n",
        "    Document(page_content=img_base64,\n",
        "             metadata={id_key: str(uuid.uuid4())})\n",
        "    for img_base64 in img_base64_list\n",
        "]\n",
        "\n",
        "doc_ids = [doc.metadata[id_key] for doc in chunks_documents]\n",
        "\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(text_summaries + table_summaries + image_summaries)\n",
        "]\n",
        "\n",
        "retriever_multi_vector_img.docstore.mset(list(zip(doc_ids, chunks_documents)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 7776,
          "status": "ok",
          "timestamp": 1736425772561,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "H0_N7DZDX0vH",
        "outputId": "f9a575dd-5ebb-4ca0-d44d-204158f6438c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def batch(iterable, batch_size=1000):\n",
        "    for i in range(0, len(iterable), batch_size):\n",
        "        yield iterable[i:i + batch_size]\n",
        "\n",
        "# Split to batches with a max size of 1,000\n",
        "batch_size = 1000\n",
        "batches = list(batch(summary_docs, batch_size))\n",
        "\n",
        "for batch_docs in batches:\n",
        "    retriever_multi_vector_img.vectorstore.add_documents(batch_docs)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "part1_multimodal_rag_langchain (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
