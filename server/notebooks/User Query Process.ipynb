{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NDsTUvKjwHBW"
      },
      "source": [
        "# Multimodal Retrieval Augmented Generation (RAG) with Gemini, Vertex AI Vector Search, and LangChain\n",
        "\n",
        "---\n",
        "\n",
        "# Part 2: User Query Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXJpXzKrh2rJ"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5afkyDMSBW5"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "executionInfo": {
          "elapsed": 11582,
          "status": "ok",
          "timestamp": 1736325868458,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "kc4WxYmLSBW5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -U -q google-cloud-aiplatform langchain-core langchain-google-vertexai langchain-text-splitters langchain-community \"unstructured[all-docs]\" pypdf pydantic lxml pillow matplotlib opencv-python tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 381,
          "status": "ok",
          "timestamp": 1736325873243,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "XRvKdaPDTznN",
        "outputId": "6f79507c-186a-433d-f927-deab04844f2f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsU9Bw9h2rL"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1736325880429,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "GpYEyLsOh2rL",
        "outputId": "1c362706-22ea-450d-d088-59e212d6d82f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1vKZZoEh2rL"
      },
      "source": [
        "### Define Google Cloud project information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 438,
          "status": "ok",
          "timestamp": 1736325894403,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "gJqZ76rJh2rM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"sublime-vine-445509-s8\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# For Vector Search Staging\n",
        "GCS_BUCKET = \"hashem_yaazor\"  # @param {type:\"string\"}\n",
        "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57262621bd1c"
      },
      "source": [
        "### Initialize the Vertex AI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3299,
          "status": "ok",
          "timestamp": 1736325899797,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "D48gUW5-h2rM",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=GCS_BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuQwwRiniVFG"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2736,
          "status": "ok",
          "timestamp": 1736325906309,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "rtMowvm-yQ97",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import os\n",
        "import re\n",
        "\n",
        "from IPython.display import Image, Markdown, display\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_google_vertexai import (\n",
        "    ChatVertexAI,\n",
        "    VectorSearchVectorStore,\n",
        "    VertexAIEmbeddings,\n",
        ")\n",
        "from langchain_google_vertexai.vectorstores.document_storage import GCSDocumentStorage\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf3ee5d1686"
      },
      "source": [
        "### Define model information\n",
        "\n",
        "- [Vertex AI - Model Information](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 405,
          "status": "ok",
          "timestamp": 1736325909550,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "eb39bdada39d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gemini-1.5-flash\"\n",
        "GEMINI_OUTPUT_TOKEN_LIMIT = 8192\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-004\"\n",
        "EMBEDDING_TOKEN_LIMIT = 2048\n",
        "\n",
        "TOKEN_LIMIT = min(GEMINI_OUTPUT_TOKEN_LIMIT, EMBEDDING_TOKEN_LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLo773i5gPcp"
      },
      "source": [
        "### Define index information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dtwDaeKg5-4"
      },
      "source": [
        "Connect to exist vertex AI vector search:\n",
        "\n",
        "*   Copy index id from https://console.cloud.google.com/vertex-ai/matching-engine/indexes\n",
        "*   Copy endpoint id from https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "executionInfo": {
          "elapsed": 397,
          "status": "ok",
          "timestamp": 1736325914513,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "gaSaeG3tf3d4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "INDEX_ID = '4488078921232809984' #@param {type: \"string\"}\n",
        "ENDPOINT_ID = '7764658756377378816' #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd8475f61ef9"
      },
      "source": [
        "## Create retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487ad4e4ccac"
      },
      "source": [
        "- Create [`VectorSearchVectorStore`](https://api.python.langchain.com/en/latest/vectorstores/langchain_google_vertexai.vectorstores.vectorstores.VectorSearchVectorStore.html) with Vector Search Index ID and Endpoint ID.\n",
        "- Use [`textembedding-gecko`](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings) as embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 452,
          "status": "ok",
          "timestamp": 1736325918694,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "e49355d04889",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# The vectorstore to use to index the summaries\n",
        "vectorstore = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=LOCATION,\n",
        "    gcs_bucket_name=GCS_BUCKET,\n",
        "    index_id=INDEX_ID,\n",
        "    endpoint_id=ENDPOINT_ID,\n",
        "    embedding=VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
        "    stream_update=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67a4b0490b45"
      },
      "source": [
        "- Create Multi-Vector Retriever using the vector store you created.\n",
        "- Since vector stores only contain the embedding and an ID, you'll also need to create a document store indexed by ID to get the original source documents after searching for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 395,
          "status": "ok",
          "timestamp": 1736325924727,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "1eVH5GhWtdJI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(GCS_BUCKET)\n",
        "    if not bucket.exists():\n",
        "        raise ValueError(f\"Bucket '{GCS_BUCKET}' does not exist.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 547,
          "status": "ok",
          "timestamp": 1736325927521,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "8e92ff890483",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "docstore = GCSDocumentStorage(bucket, \"RFM_chunks\")\n",
        "\n",
        "id_key = \"doc_id\"\n",
        "retriever_multi_vector_img = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=docstore,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b665ead18f3b"
      },
      "source": [
        "## Create Chain with Retriever and Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 430,
          "status": "ok",
          "timestamp": 1736325931020,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "wi-EVr-zOR63",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def looks_like_base64(sb):\n",
        "    \"\"\"Check if the string looks like base64\"\"\"\n",
        "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n",
        "\n",
        "\n",
        "def is_image_data(b64data):\n",
        "    \"\"\"\n",
        "    Check if the base64 data is an image by looking at the start of the data\n",
        "    \"\"\"\n",
        "    image_signatures = {\n",
        "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
        "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
        "        b\"\\xa47\\x49\\x46\\x38\": \"gif\",\n",
        "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
        "    }\n",
        "    try:\n",
        "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
        "        for sig, format in image_signatures.items():\n",
        "            if header.startswith(sig):\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def split_image_text_types(docs):\n",
        "    \"\"\"\n",
        "    Split base64-encoded images and texts\n",
        "    \"\"\"\n",
        "    b64_images = []\n",
        "    texts = []\n",
        "    for doc in docs:\n",
        "        # Check if the document is of type Document and extract page_content if so\n",
        "        if isinstance(doc, Document):\n",
        "            doc = doc.page_content\n",
        "        if looks_like_base64(doc) and is_image_data(doc):\n",
        "            b64_images.append(doc)\n",
        "        else:\n",
        "            texts.append(doc)\n",
        "    return {\"images\": b64_images, \"texts\": texts}\n",
        "\n",
        "\n",
        "def img_prompt_func(data_dict):\n",
        "    \"\"\"\n",
        "    Join the context into a single string\n",
        "    \"\"\"\n",
        "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
        "    messages = [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": (\n",
        "                \"\"\"You are a learning assistant tasked with helping trainees in\\\n",
        "                 the pilot course understand the 'Ofer' helicopter systems and \\\n",
        "                 operating instructions. You will receive a mix of content, \\\n",
        "                 including text, tables, and images, often in the form of charts\\\n",
        "                  or graphs.\n",
        "Provide clear, accurate, and professional answers to the user's questions about\\\n",
        " the helicopter, using the information provided. Your responses should focus \\\n",
        " exclusively on addressing the user's question in a concise and professional \\\n",
        " manner, based on the materials you receive. Do not include any remarks about \\\n",
        " the source of the materials, their format, or how they were compiled. Simply \\\n",
        " deliver the most relevant and comprehensive answer to the question, ensuring \\\n",
        " it aligns with the provided information.\"\"\"\n",
        "                f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
        "                \"Text and / or tables:\\n\"\n",
        "                f\"{formatted_texts}\"\n",
        "            ),\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Adding image(s) to the messages if present\n",
        "    if data_dict[\"context\"][\"images\"]:\n",
        "        for image in data_dict[\"context\"][\"images\"]:\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "                }\n",
        "            )\n",
        "    return [HumanMessage(content=messages)]\n",
        "\n",
        "# Create RAG chain\n",
        "chain_multimodal_rag = (\n",
        "    {\n",
        "        \"context\": RunnableLambda(lambda x: source_docs),\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | RunnableLambda(img_prompt_func)\n",
        "    | ChatVertexAI(\n",
        "        temperature=0,\n",
        "        model_name=MODEL_NAME,\n",
        "        max_output_tokens=TOKEN_LIMIT,\n",
        "    )  # Multi-modal LLM\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 410,
          "status": "ok",
          "timestamp": 1736325937806,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "MozFDl7q2V9Z",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def sources_details(docs):\n",
        "    docs_details = {}\n",
        "    for doc in docs:\n",
        "        if doc.metadata['filename'] in docs_details:\n",
        "            docs_details[doc.metadata['filename']].append(int(doc.metadata['page_number']) + 1)\n",
        "        else:\n",
        "            docs_details[doc.metadata['filename']] = [int(doc.metadata['page_number']) + 1]\n",
        "    return docs_details\n",
        "\n",
        "def sources_details_string(docs):\n",
        "    sources = sources_details(docs)\n",
        "\n",
        "    sources_strings = []\n",
        "    for key, val in sources.items():\n",
        "        pages = ', '.join(map(str, val))\n",
        "        page_word = \"page\" if len(val) == 1 else \"pages\"\n",
        "        sources_strings.append(f'The file \"{key}\" {page_word} {pages}')\n",
        "\n",
        "    result = 'The answer is based on the following files:\\n' + '\\n'.join(sources_strings)\n",
        "    return result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2925d397fdbb"
      },
      "source": [
        "## User query process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1736325941445,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "b3b445f934a8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\"what is palacards?\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1046,
          "status": "ok",
          "timestamp": 1736325947037,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "8-fOTGQ21-iJ",
        "outputId": "e902721b-ac7a-47ce-bd43-fe24121f747a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "docs = retriever_multi_vector_img.invoke(query, limit=10)\n",
        "source_docs = split_image_text_types(docs)\n",
        "source_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6172a22b1203"
      },
      "source": [
        "### Get Retrieved documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd784ce7f205"
      },
      "source": [
        "### Get generative response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "executionInfo": {
          "elapsed": 781,
          "status": "ok",
          "timestamp": 1736325963030,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "4c5f936f89da",
        "outputId": "63cc3905-aaa6-4e9c-b171-d1a9e0a42b61",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "result = chain_multimodal_rag.invoke(query)\n",
        "\n",
        "Markdown(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 392,
          "status": "ok",
          "timestamp": 1736325967299,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "bVGp9TwJwEse",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/sublime-vine-445509-s8-e9eb269d62b2.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "executionInfo": {
          "elapsed": 7,
          "status": "error",
          "timestamp": 1736326060322,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "0ar6YIf1tM4Q",
        "outputId": "30b28271-70d5-4acb-f845-28086d0f06b2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "def generate_signed_url(folder, filename):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(GCS_BUCKET)\n",
        "    blob = bucket.blob(os.path.join(folder, filename))\n",
        "\n",
        "    url = blob.generate_signed_url(\n",
        "        version=\"v4\",\n",
        "        expiration=timedelta(hours=1),\n",
        "        method=\"GET\",\n",
        "    )\n",
        "\n",
        "    return url\n",
        "\n",
        "folder = \"ofer_documents\"\n",
        "filename = \"RFM עדכון 8.2.24.pdf\"\n",
        "url = generate_signed_url(folder, filename)\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "executionInfo": {
          "elapsed": 413,
          "status": "error",
          "timestamp": 1736326043323,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "EfZw5tVU1Hb-",
        "outputId": "29ce0564-028d-41a0-8335-09bf9c75fa50",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def list_blobs_with_prefix(bucket_name, prefix):\n",
        "    storage_client = storage.Client()\n",
        "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
        "\n",
        "    urls = []\n",
        "    for blob in blobs:\n",
        "        url = blob.public_url\n",
        "        urls.append(url)\n",
        "\n",
        "    return urls\n",
        "\n",
        "prefix = \"ofer_documents\"\n",
        "urls = list_blobs_with_prefix(GCS_BUCKET, prefix)\n",
        "print(urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 402,
          "status": "ok",
          "timestamp": 1736257040599,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "v44czLCysdmZ",
        "outputId": "ba87f437-f634-45a3-be57-aaf37f92d180",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "files = sources_details(texts_docs)\n",
        "files_string = sources_details_string(texts_docs)\n",
        "print(files.keys())\n",
        "for file in files.keys():\n",
        "    print(f\"File: {file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 379,
          "status": "ok",
          "timestamp": 1736257046277,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "5nQBX4QdfDvs",
        "outputId": "491aad3a-1935-4238-e825-7d2bbf6e31e1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "folder = \"pdf_documents\"\n",
        "\n",
        "texts_docs = [doc for doc in docs if not looks_like_base64(doc.page_content) and not is_image_data(doc.page_content)]\n",
        "files = sources_details(texts_docs)\n",
        "for file in files.keys():\n",
        "    print(generate_signed_url(folder, file))\n",
        "\n",
        "for i in source_docs[\"images\"]:\n",
        "    display(Image(base64.b64decode(i)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "part2_multimodal_rag_langchain (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
